{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from RNN import *\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock = \"AAPL\"  # 根据需要更改股票代码\n",
    "# train_df = pd.read_csv(f'/homes/Adam/DL_A3/us_data/train/{stock}.csv')\n",
    "# test_df = pd.read_csv(f'/homes/Adam/DL_A3/us_data/test/{stock}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_and_combine_data(folder_path):\n",
    "    all_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# 定义训练和测试数据的文件夹路径\n",
    "train_folder = '/homes/Adam/DL_A3/stock_train'\n",
    "test_folder = '/homes/Adam/DL_A3/stock_test'\n",
    "\n",
    "# 读取和合并训练数据\n",
    "train_df = read_and_combine_data(train_folder)\n",
    "\n",
    "# 读取和合并测试数据\n",
    "test_df = read_and_combine_data(test_folder)\n",
    "\n",
    "# 接下来，您可以对 train_df 和 test_df 进行进一步的处理和分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "\n",
    "# Create detailed labels for training and testing datasets\n",
    "train_detailed_labels = StockPricePredictor.create_labels(train_df['$close'],sequence_length)\n",
    "test_detailed_labels = StockPricePredictor.create_labels(test_df['$close'],sequence_length)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_detailed_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_detailed_labels)\n",
    "\n",
    "# Select features\n",
    "selected_features = ['$volume', 'daily_return', 'volatility', 'RSI', 'MA_diff']\n",
    "\n",
    "X_train = train_df[selected_features].values\n",
    "X_test = test_df[selected_features].values\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_sequences = StockPricePredictor.create_sequences(X_train_scaled, sequence_length)\n",
    "X_test_sequences = StockPricePredictor.create_sequences(X_test_scaled, sequence_length)\n",
    "\n",
    "# Adjust labels for sequences\n",
    "\n",
    "y_train_sequences = train_labels_encoded[sequence_length:]\n",
    "y_test_sequences = test_labels_encoded[sequence_length:]\n",
    "\n",
    "\n",
    "\n",
    "# 分割原始训练数据集为新的训练集和验证集\n",
    "X_train_new, X_val, y_train_new, y_val = train_test_split(\n",
    "    X_train_sequences, y_train_sequences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 转换为 PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_new, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_new, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_sequences, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_sequences, dtype=torch.long)\n",
    "\n",
    "# 创建 DataLoader 实例\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 'Decrease': 9464 occurrences\n",
      "Label 'Increase': 19692 occurrences\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用 Counter 来计数每个类别的出现次数\n",
    "label_counts = Counter(train_detailed_labels)\n",
    "\n",
    "# 打印每个类别的数量\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label '{label}': {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/homes/Adam/DL_A3/ASM3.ipynb 单元格 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617669645f33303930227d/homes/Adam/DL_A3/ASM3.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "RNN Test Accuracy: 87.70%, Loss: 0.5291, Precision: 0.8881, Recall: 0.8900, F1 Score: 0.8891, AUC-ROC: 0.9128\n"
     ]
    }
   ],
   "source": [
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", is_cuda_available)\n",
    "\n",
    "# Model instantiation\n",
    "input_size = len(selected_features)\n",
    "hidden_size = 10\n",
    "num_layers = 3\n",
    "num_epochs = 100\n",
    "dropout_rate = 0.1  # 确保这里的 dropout 率与您初始化模型时的一致\n",
    "\n",
    "# Instantiate and move the model to GPU if available\n",
    "rnn_model = StockRNN(input_size, hidden_size, num_layers, dropout_rate)\n",
    "if is_cuda_available:\n",
    "    rnn_model = rnn_model.cuda()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.0005)\n",
    "\n",
    "# Train the model\n",
    "rnn_best_model_state, rnn_train_losses, rnn_val_losses, rnn_train_metrics, rnn_val_metrics = train_model(\n",
    "    rnn_model, train_loader, val_loader, test_loader, criterion, optimizer, num_epochs\n",
    ")\n",
    "\n",
    "# Load the best model state\n",
    "rnn_model.load_state_dict(rnn_best_model_state)\n",
    "\n",
    "# Evaluate the performance of the trained model\n",
    "rnn_model.eval()  # Set the model to evaluation mode\n",
    "rnn_test_accuracy, rnn_test_loss, rnn_test_precision, rnn_test_recall, rnn_test_f1, rnn_test_auc_roc = evaluate_accuracy_and_loss(rnn_model, test_loader, criterion)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"RNN Test Accuracy: {rnn_test_accuracy:.2f}%, Loss: {rnn_test_loss:.4f}, Precision: {rnn_test_precision:.4f}, Recall: {rnn_test_recall:.4f}, F1 Score: {rnn_test_f1:.4f}, AUC-ROC: {rnn_test_auc_roc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print(\"Best Model Performance:\")\n",
    "# print(f\"Accuracy: {best_accuracy:.2f}%, Loss: {best_loss:.4f}, Precision: {best_precision:.4f}, Recall: {best_recall:.4f}, F1 Score: {best_f1:.4f}, AUC-ROC: {best_auc_roc:.4f}\")\n",
    "\n",
    "# # 绘制损失图\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(rnn_train_losses, label='Train Loss')\n",
    "# plt.plot(rnn_test_losses, label='Test Loss')\n",
    "# plt.plot(rnn_val_losses, label='Validation Loss')  # 加入验证集损失的绘制\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Train vs Test vs Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test Accuracy: 77.10%, Loss: 2.0240, Precision: 0.9027, Recall: 0.6887, F1 Score: 0.7814, AUC-ROC: 0.8422\n"
     ]
    }
   ],
   "source": [
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", is_cuda_available)\n",
    "\n",
    "# Model instantiation\n",
    "input_size = len(selected_features)\n",
    "hidden_size = 10\n",
    "num_layers = 3\n",
    "dropout_rate = 0.8  # 确保使用与训练时相同的 dropout 率\n",
    "\n",
    "# 实例化模型并在有 GPU 的情况下移到 GPU\n",
    "LSTM_model = StockLSTM(input_size, hidden_size, num_layers, dropout_rate)\n",
    "if is_cuda_available:\n",
    "    LSTM_model = LSTM_model.cuda()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=0.0005)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 300\n",
    "lstm_best_model_state, lstm_train_losses, lstm_val_losses, lstm_train_metrics, lstm_val_metrics = train_model(\n",
    "    LSTM_model, train_loader, val_loader, test_loader, criterion, optimizer, num_epochs\n",
    ")\n",
    "\n",
    "# 加载最佳模型状态\n",
    "LSTM_model.load_state_dict(lstm_best_model_state)\n",
    "\n",
    "# 使用训练好的模型进行评估\n",
    "LSTM_model.eval()  # Set the model to evaluation mode\n",
    "lstm_test_accuracy, lstm_test_loss, lstm_test_precision, lstm_test_recall, lstm_test_f1, lstm_test_auc_roc = evaluate_accuracy_and_loss(LSTM_model, test_loader, criterion)\n",
    "\n",
    "# 打印评估结果\n",
    "print(f\"LSTM Test Accuracy: {lstm_test_accuracy:.2f}%, Loss: {lstm_test_loss:.4f}, Precision: {lstm_test_precision:.4f}, Recall: {lstm_test_recall:.4f}, F1 Score: {lstm_test_f1:.4f}, AUC-ROC: {lstm_test_auc_roc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GRU Test Accuracy: 76.98%, Loss: 1.6261, Precision: 0.8999, Recall: 0.6892, F1 Score: 0.7806, AUC-ROC: 0.8335\n"
     ]
    }
   ],
   "source": [
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", is_cuda_available)\n",
    "\n",
    "# Model instantiation\n",
    "input_size = len(selected_features)\n",
    "hidden_size = 10\n",
    "num_layers = 3\n",
    "dropout_rate = 0.1  # 确保使用与训练时相同的 dropout 率\n",
    "\n",
    "# 实例化模型并在有 GPU 的情况下移到 GPU\n",
    "GRU_model = StockGRU(input_size, hidden_size, num_layers, dropout_rate)\n",
    "if is_cuda_available:\n",
    "    GRU_model = GRU_model.cuda()\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(GRU_model.parameters(), lr=0.0005)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 200\n",
    "gru_best_model_state, gru_train_losses, gru_val_losses, gru_train_metrics, gru_val_metrics = train_model(\n",
    "    GRU_model, train_loader, val_loader, test_loader, criterion, optimizer, num_epochs\n",
    ")\n",
    "\n",
    "# 加载最佳模型状态\n",
    "GRU_model.load_state_dict(gru_best_model_state)\n",
    "\n",
    "# 使用训练好的模型进行评估\n",
    "GRU_model.eval()  # Set the model to evaluation mode\n",
    "gru_test_accuracy, gru_test_loss, gru_test_precision, gru_test_recall, gru_test_f1, gru_test_auc_roc = evaluate_accuracy_and_loss(GRU_model, test_loader, criterion)\n",
    "\n",
    "# 打印评估结果\n",
    "print(f\"GRU Test Accuracy: {gru_test_accuracy:.2f}%, Loss: {gru_test_loss:.4f}, Precision: {gru_test_precision:.4f}, Recall: {gru_test_recall:.4f}, F1 Score: {gru_test_f1:.4f}, AUC-ROC: {gru_test_auc_roc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best Model Performance:\")\n",
    "# print(f\"Epoch: {gru_best_epoch_metrics[0]}, Accuracy: {gru_best_epoch_metrics[1]:.2f}%, Loss: {gru_best_epoch_metrics[2]:.4f}, Precision: {gru_best_epoch_metrics[3]:.4f}, Recall: {gru_best_epoch_metrics[4]:.4f}, F1 Score: {gru_best_epoch_metrics[5]:.4f}, AUC-ROC: {gru_best_epoch_metrics[6]:.4f}\")\n",
    "\n",
    "# # 绘制损失图\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(gru_train_losses, label='Train Loss')\n",
    "# plt.plot(gru_test_losses, label='Test Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Train vs Test Loss')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
